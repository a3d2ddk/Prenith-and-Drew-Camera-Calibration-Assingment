{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9972dc-a709-49bc-a9cb-adc696b230b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install gradio\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a67383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from utils import Cam, Img, IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6bb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Render:\n",
    "    @staticmethod\n",
    "    def draw_coordinate_frame(image_points, img):\n",
    "        x0, y0 = image_points[:,0].astype(int)\n",
    "        cv2.circle(img, (x0, y0), 9, (0, 0, 0), -1)\n",
    "\n",
    "        x1, y1 = image_points[:,1].astype(int)\n",
    "        img = cv2.arrowedLine(img, (x0, y0), (x1, y1), (255, 0, 0), 5)\n",
    "\n",
    "        x2, y2 = image_points[:,2].astype(int)\n",
    "        img = cv2.arrowedLine(img, (x0, y0), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "        x3, y3 = image_points[:,3].astype(int)\n",
    "        img = cv2.arrowedLine(img, (x0, y0), (x3, y3), (0, 0, 255), 5)\n",
    "        \n",
    "    @staticmethod\n",
    "    def image_axis():\n",
    "        return\n",
    "    @staticmethod\n",
    "    def image_cal_marks():\n",
    "        return\n",
    "\n",
    "# Main calibration workflow\n",
    "class CalibrationWorkflow:\n",
    "    \"\"\"Main calibration workflow using static helper classes\"\"\"\n",
    "    \n",
    "    def __init__(self, board_size=(9, 6), square_size=25.0, output_dir=\"/content/images\"):\n",
    "        self.board_size = board_size\n",
    "        self.square_size = square_size\n",
    "        self.output_dir = output_dir\n",
    "        self.obj_points = []\n",
    "        self.img_points = []\n",
    "        self.processed_images = []\n",
    "        self.calibration_results = None\n",
    "    \n",
    "    def process_images(self, files):\n",
    "        \"\"\"Process uploaded images and detect chessboard corners\"\"\"\n",
    "        imgs = IO.get_images()\n",
    "        if not files and not imgs:\n",
    "            return \"No files uploaded!\"\n",
    "\n",
    "        IO.store_images(files)\n",
    "        self.imgs = IO.get_images()\n",
    "\n",
    "        self.opoints, self.ipoints = Img.find_chessboard_corners(imgs)\n",
    "\n",
    "        #IO.save_calibration_results([opoints, ipoints])\n",
    "        \"\"\"\n",
    "        for images in imgs:\n",
    "            ret, lam, dist, rvecs, tau = cv.calibrateCamera(opoints, ipoints, images.shape[::-1], None, None)\n",
    "\n",
    "            rvecs = rvecs[0]\n",
    "            omega = cv.Rodrigues(rvecs)\n",
    "            omega = omega[0]\n",
    "            tau = tau[0]\n",
    "            print(omega)\n",
    "        \"\"\"\n",
    "        return \"Calibration Complete\"\n",
    "    \n",
    "    def get_camera_pose_plot(self):\n",
    "        \"\"\"Get camera pose visualization\"\"\"\n",
    "        if not self.calibration_results:\n",
    "            return None\n",
    "        \n",
    "        return Render.create_camera_pose_plot(\n",
    "            self.calibration_results['rvecs'],\n",
    "            self.calibration_results['tvecs']\n",
    "        )\n",
    "    \n",
    "    def get_sample_images_with_axes(self, num_samples=8):\n",
    "        \"\"\"Get sample images with coordinate axes drawn\"\"\"\n",
    "        images = []\n",
    "        for i in range(5):\n",
    "            img = self.imgs[i]\n",
    "\n",
    "            ret, lam, dist, rvecs, tau = cv.calibrateCamera(self.opoints, self.ipoints, img.shape[::-1], None, None)\n",
    "\n",
    "            rvecs = rvecs[0]\n",
    "            omega = cv.Rodrigues(rvecs)\n",
    "            omega = omega[0]\n",
    "            tau = tau[0]\n",
    "\n",
    "            W = 2 * np.array([\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ], dtype=np.float64)\n",
    "\n",
    "            image_axes, jac = cv.projectPoints(W, rvecs, tau, lam, dist)\n",
    "\n",
    "            image_axes = image_axes.squeeze().T\n",
    "\n",
    "            x0, y0 = image_axes[:,0].astype(int)\n",
    "            cv.circle(img, (x0, y0), 9, (0, 0, 0), -1)\n",
    "\n",
    "            x1, y1 = image_axes[:,1].astype(int)\n",
    "            img = cv.arrowedLine(img, (x0, y0), (x1, y1), (255, 0, 0), 5)\n",
    "\n",
    "            x2, y2 = image_axes[:,2].astype(int)\n",
    "            img = cv.arrowedLine(img, (x0, y0), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "            x3, y3 = image_axes[:,3].astype(int)\n",
    "            img = cv.arrowedLine(img, (x0, y0), (x3, y3), (0, 0, 255), 5)\n",
    "\n",
    "            pil = Image.fromarray(img)\n",
    "\n",
    "            images.append(pil)\n",
    "\n",
    "        return images[0], images[1], images[2], images[3], images[4]\n",
    "    \n",
    "    def get_undistortion_preview(self):\n",
    "        \"\"\"Get undistortion before/after comparison\"\"\"\n",
    "        test_img = self.imgs[18]\n",
    "        ret, lam, dist, rvecs, tau = cv.calibrateCamera(self.opoints, self.ipoints, test_img.shape[::-1], None, None)\n",
    "\n",
    "        new_img = Img.undistort_image(test_img, lam, dist)\n",
    "\n",
    "        original_pil = Image.fromarray(test_img)\n",
    "        undistorted_pil = Image.fromarray(new_img)\n",
    "\n",
    "        return undistorted_pil, undistorted_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f12d4723-5dd7-4724-9e66-7a73f523aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "* Running on public URL: https://d8c0ba0f1dc42556e1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d8c0ba0f1dc42556e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create workflow instance\n",
    "workflow = CalibrationWorkflow()\n",
    "\n",
    "# Gradio interface\n",
    "with gr.Blocks(title=\"Camera Calibration\") as demo:\n",
    "    gr.Markdown(\"#Camera Calibration Interface\")\n",
    "    gr.Markdown(\"Upload chessboard images and run calibration with visualization\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        files = gr.File(file_count=\"multiple\", file_types=[\".jpeg\"])\n",
    "        process_btn = gr.Button(\"Process Images\")\n",
    "    \n",
    "    process_status = gr.Textbox(label=\"Processing Status\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"Camera Poses\"):\n",
    "            pose_btn = gr.Button(\"Show Camera Poses\")\n",
    "            pose_plot = gr.Plot()\n",
    "        \n",
    "        with gr.Tab(\"Sample Images\"):\n",
    "            sample_btn = gr.Button(\"Show Images with Axes\")\n",
    "            with gr.Row():\n",
    "                img1 = gr.Image(label=\"Sample 1\")\n",
    "                img2 = gr.Image(label=\"Sample 2\")\n",
    "                img3 = gr.Image(label=\"Sample 3\")\n",
    "                img4 = gr.Image(label=\"Sample 4\")\n",
    "                img5 = gr.Image(label=\"Sample 5\")\n",
    "        \n",
    "        with gr.Tab(\"Undistortion\"):\n",
    "            undist_btn = gr.Button(\"Show Undistortion Preview\")\n",
    "            with gr.Row():\n",
    "                original = gr.Image(label=\"Original\")\n",
    "                undistorted = gr.Image(label=\"Undistorted\")\n",
    "    \n",
    "    # Event handlers\n",
    "    process_btn.click(\n",
    "        workflow.process_images, \n",
    "        inputs=[files], \n",
    "        outputs=[process_status]\n",
    "    )\n",
    "    \n",
    "    pose_btn.click(\n",
    "        workflow.get_camera_pose_plot, \n",
    "        outputs=[pose_plot]\n",
    "    )\n",
    "    \n",
    "    sample_btn.click(\n",
    "        workflow.get_sample_images_with_axes, \n",
    "        outputs=[img1, img2, img3, img4, img5]\n",
    "    )\n",
    "    \n",
    "    undist_btn.click(\n",
    "        workflow.get_undistortion_preview, \n",
    "        outputs=[original, undistorted]\n",
    "    )\n",
    "\n",
    "# Launch interface\n",
    "app = demo.launch(share=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07117657-da21-4195-91a9-8f15d91a5c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
