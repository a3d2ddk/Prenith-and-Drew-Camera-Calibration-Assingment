{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9972dc-a709-49bc-a9cb-adc696b230b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a67383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import Cam, Img, IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e6bb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Render:\n",
    "    @staticmethod\n",
    "    def display_image():\n",
    "        return\n",
    "    @staticmethod\n",
    "    def image_axis():\n",
    "        return\n",
    "    @staticmethod\n",
    "    def image_cal_marks():\n",
    "        return\n",
    "\n",
    "# Main calibration workflow\n",
    "class CalibrationWorkflow:\n",
    "    \"\"\"Main calibration workflow using static helper classes\"\"\"\n",
    "    \n",
    "    def __init__(self, board_size=(9, 6), square_size=25.0, output_dir=\"/content/images\"):\n",
    "        self.board_size = board_size\n",
    "        self.square_size = square_size\n",
    "        self.output_dir = output_dir\n",
    "        self.obj_points = []\n",
    "        self.img_points = []\n",
    "        self.processed_images = []\n",
    "        self.calibration_results = None\n",
    "    \n",
    "    def process_images(self, files):\n",
    "        \"\"\"Process uploaded images and detect chessboard corners\"\"\"\n",
    "        imgs = IO.get_images()\n",
    "        if not files and not imgs:\n",
    "            return \"No files uploaded!\"\n",
    "\n",
    "        IO.store_images(files)\n",
    "        imgs = IO.get_images()\n",
    "\n",
    "        opoints, ipoints = Img.find_chessboard_corners(imgs)\n",
    "\n",
    "        ret, lam, dist, rvecs, tau = cv.calibrateCamera(opoints, ipoints, imgs[0].shape[::-1], None, None)\n",
    "\n",
    "        omega = cv.Rodrigues(rvecs[0])\n",
    "        tau = tau[0]\n",
    "        IO.save_calibration_results([lam, dist, omega, rvecs, tau])\n",
    "\n",
    "        return\n",
    "    \n",
    "    def get_camera_pose_plot(self):\n",
    "        \"\"\"Get camera pose visualization\"\"\"\n",
    "        if not self.calibration_results:\n",
    "            return None\n",
    "        \n",
    "        return Render.create_camera_pose_plot(\n",
    "            self.calibration_results['rvecs'],\n",
    "            self.calibration_results['tvecs']\n",
    "        )\n",
    "    \n",
    "    def get_sample_images_with_axes(self, num_samples=8):\n",
    "        \"\"\"Get sample images with coordinate axes drawn\"\"\"\n",
    "        if not self.calibration_results or not self.processed_images:\n",
    "            return [None] * num_samples\n",
    "        \n",
    "        images = []\n",
    "        for i in range(min(num_samples, len(self.processed_images))):\n",
    "            img = Img.load_image(self.processed_images[i])\n",
    "            \n",
    "            \n",
    "            img_with_axes = Render.draw_coordinate_axes(\n",
    "                img,\n",
    "                self.calibration_results['rvecs'][i],\n",
    "                self.calibration_results['tvecs'][i],\n",
    "                self.calibration_results['mtx'],\n",
    "                self.calibration_results['dist']\n",
    "            )\n",
    "\n",
    "            images.append(Img.bgr_to_rgb(img_with_axes))\n",
    "        \n",
    "        # Pad with None if needed\n",
    "        while len(images) < num_samples:\n",
    "            images.append(None)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def get_undistortion_preview(self):\n",
    "        \"\"\"Get undistortion before/after comparison\"\"\"\n",
    "        if not self.calibration_results or not self.processed_images:\n",
    "            return None, None\n",
    "        \n",
    "        img = Img.load_image(self.processed_images[0])\n",
    "        undistorted = Cam.undistort_image(\n",
    "            img, \n",
    "            self.calibration_results['mtx'], \n",
    "            self.calibration_results['dist']\n",
    "        )\n",
    "        \n",
    "        return Img.bgr_to_rgb(img), Img.bgr_to_rgb(undistorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f12d4723-5dd7-4724-9e66-7a73f523aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* Running on public URL: https://9f12484940e0afbfca.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9f12484940e0afbfca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./content/images/image_18.jpeg\n",
      "./content/images/image_19.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/gradio/queueing.py\", line 667, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/gradio/route_utils.py\", line 349, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/gradio/blocks.py\", line 2274, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/gradio/blocks.py\", line 1781, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/addk3/anaconda3/envs/vision/lib/python3.13/site-packages/gradio/utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_39557/636044483.py\", line 40, in process_images\n",
      "    IO.save_calibration_results([lam, dist, omega, rvecs, tau])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/addk3/Public/projects/camera-calibration/utils.py\", line 97, in save_calibration_results\n",
      "    print(f\"Error saving calibration results: {e}\")\n",
      "                                               ^\n",
      "NameError: name 'e' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Create workflow instance\n",
    "workflow = CalibrationWorkflow()\n",
    "\n",
    "# Gradio interface\n",
    "with gr.Blocks(title=\"Camera Calibration\") as demo:\n",
    "    gr.Markdown(\"#Camera Calibration Interface\")\n",
    "    gr.Markdown(\"Upload chessboard images and run calibration with visualization\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        files = gr.File(file_count=\"multiple\", file_types=[\".jpeg\"])\n",
    "        process_btn = gr.Button(\"Process Images\")\n",
    "    \n",
    "    process_status = gr.Textbox(label=\"Processing Status\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"Camera Poses\"):\n",
    "            pose_btn = gr.Button(\"Show Camera Poses\")\n",
    "            pose_plot = gr.Plot()\n",
    "        \n",
    "        with gr.Tab(\"Sample Images\"):\n",
    "            sample_btn = gr.Button(\"Show Images with Axes\")\n",
    "            with gr.Row():\n",
    "                img1 = gr.Image(label=\"Sample 1\")\n",
    "                img2 = gr.Image(label=\"Sample 2\")\n",
    "                img3 = gr.Image(label=\"Sample 3\")\n",
    "                img4 = gr.Image(label=\"Sample 4\")\n",
    "                img5 = gr.Image(label=\"Sample 5\")\n",
    "        \n",
    "        with gr.Tab(\"Undistortion\"):\n",
    "            undist_btn = gr.Button(\"Show Undistortion Preview\")\n",
    "            with gr.Row():\n",
    "                original = gr.Image(label=\"Original\")\n",
    "                undistorted = gr.Image(label=\"Undistorted\")\n",
    "    \n",
    "    # Event handlers\n",
    "    process_btn.click(\n",
    "        workflow.process_images, \n",
    "        inputs=[files], \n",
    "        outputs=[process_status]\n",
    "    )\n",
    "    \n",
    "    pose_btn.click(\n",
    "        workflow.get_camera_pose_plot, \n",
    "        outputs=[pose_plot]\n",
    "    )\n",
    "    \n",
    "    sample_btn.click(\n",
    "        workflow.get_sample_images_with_axes, \n",
    "        outputs=[img1, img2, img3, img4, img5]\n",
    "    )\n",
    "    \n",
    "    undist_btn.click(\n",
    "        workflow.get_undistortion_preview, \n",
    "        outputs=[original, undistorted]\n",
    "    )\n",
    "\n",
    "# Launch interface\n",
    "app = demo.launch(share=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07117657-da21-4195-91a9-8f15d91a5c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
